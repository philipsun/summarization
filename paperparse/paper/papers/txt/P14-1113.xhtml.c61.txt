 This paper proposes a novel method for semantic hierarchy construction based on word embeddings, which are trained using a large-scale corpus. Using the word embeddings, we learn the hypernym u'\u2013' hyponym relationship by estimating projection matrices which map words to their hypernyms. Further improvements are made using a cluster-based approach in order to model the more fine-grained relations. Then we propose a few simple criteria to identity whether a new word pair is a hypernym u'\u2013' hyponym relation. Based on the pairwise hypernym u'\u2013' hyponym relations, we build semantic hierarchies automatically. In our experiments, the proposed method significantly outperforms state-of-the-art methods and achieves the best F1-score of 73.74% on a manually labeled test dataset. Further experiments show that our method is complementary to the previous manually-built hierarchy extension methods. For future work, we aim to improve word embedding learning under the guidance of hypernym u'\u2013' hyponym relations. By including the hypernym u'\u2013' hyponym relation constraints while training word embeddings, we expect to improve the embeddings such that they become more suitable for this task.