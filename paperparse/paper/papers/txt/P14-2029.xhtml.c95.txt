 In this paper, we developed a system for predicting grammaticality on an ordinal scale and created a labeled dataset that we have released publicly (ยง 2 ) to enable more realistic evaluations in future research. Our system outperformed an existing state-of-the-art system [ 16 ] in evaluations on binary and ordinal scales. This is the most realistic evaluation of methods for predicting sentence-level grammaticality to date. Surprisingly, the system from Post ( 2011 ) performed quite poorly on the GUG dataset. We speculate that this is due to the fact that the Post system relies heavily on features extracted from automatic syntactic parses. While Post found that such a system can effectively distinguish grammatical news text sentences from sentences generated by a language model, measuring the grammaticality of real sentences from language learners seems to require a wider variety of features, including n -gram counts, language model scores, etc. Of course, our findings do not indicate that syntactic features such as those from Post ( 2011 ) are without value. In future work, it may be possible to improve grammaticality measurement by integrating such features into a larger system.